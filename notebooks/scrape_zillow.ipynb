{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zillow Web Scraper\n",
    "A simple web scraper written using scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unicodecsv in /usr/local/lib/python3.6/dist-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install unicodecsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lxml import html\n",
    "import requests\n",
    "import unicodecsv as csv\n",
    "import argparse\n",
    "\n",
    "\n",
    "def parse(zipcode, filter=None):\n",
    "    if filter == \"newest\":\n",
    "        url = \"https://www.zillow.com/homes/for_sale/{0}/0_singlestory/days_sort\".format(zipcode)\n",
    "    elif filter == \"cheapest\":\n",
    "        url = \"https://www.zillow.com/homes/for_sale/{0}/0_singlestory/pricea_sort/\".format(zipcode)\n",
    "    else:\n",
    "        url = \"https://www.zillow.com/homes/for_sale/{0}_rb/?fromHomePage=true&shouldFireSellPageImplicitClaimGA=false&fromHomePageTab=buy\".format(\n",
    "            zipcode)\n",
    "\n",
    "    for i in range(5):\n",
    "        # try:\n",
    "        headers = {\n",
    "            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'accept-encoding': 'gzip, deflate, sdch, br',\n",
    "            'accept-language': 'en-GB,en;q=0.8,en-US;q=0.6,ml;q=0.4',\n",
    "            'cache-control': 'max-age=0',\n",
    "            'upgrade-insecure-requests': '1',\n",
    "            'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        print(response.status_code)\n",
    "        parser = html.fromstring(response.text)\n",
    "        search_results = parser.xpath(\"//div[@id='search-results']//article\")\n",
    "        properties_list = []\n",
    "\n",
    "        for properties in search_results:\n",
    "            raw_address = properties.xpath(\".//span[@itemprop='address']//span[@itemprop='streetAddress']//text()\")\n",
    "            raw_city = properties.xpath(\".//span[@itemprop='address']//span[@itemprop='addressLocality']//text()\")\n",
    "            raw_state = properties.xpath(\".//span[@itemprop='address']//span[@itemprop='addressRegion']//text()\")\n",
    "            raw_postal_code = properties.xpath(\".//span[@itemprop='address']//span[@itemprop='postalCode']//text()\")\n",
    "            raw_price = properties.xpath(\".//span[@class='zsg-photo-card-price']//text()\")\n",
    "            raw_info = properties.xpath(\".//span[@class='zsg-photo-card-info']//text()\")\n",
    "            raw_broker_name = properties.xpath(\".//span[@class='zsg-photo-card-broker-name']//text()\")\n",
    "            url = properties.xpath(\".//a[contains(@class,'overlay-link')]/@href\")\n",
    "            raw_title = properties.xpath(\".//h4//text()\")\n",
    "\n",
    "            address = ' '.join(' '.join(raw_address).split()) if raw_address else None\n",
    "            city = ''.join(raw_city).strip() if raw_city else None\n",
    "            state = ''.join(raw_state).strip() if raw_state else None\n",
    "            postal_code = ''.join(raw_postal_code).strip() if raw_postal_code else None\n",
    "            price = ''.join(raw_price).strip() if raw_price else None\n",
    "            info = ' '.join(' '.join(raw_info).split()).replace(u\"\\xb7\", ',')\n",
    "            broker = ''.join(raw_broker_name).strip() if raw_broker_name else None\n",
    "            title = ''.join(raw_title) if raw_title else None\n",
    "            property_url = \"https://www.zillow.com\" + url[0] if url else None\n",
    "            is_forsale = properties.xpath('.//span[@class=\"zsg-icon-for-sale\"]')\n",
    "            properties = {\n",
    "                'address': address,\n",
    "                'city': city,\n",
    "                'state': state,\n",
    "                'postal_code': postal_code,\n",
    "                'price': price,\n",
    "                'facts and features': info,\n",
    "                'real estate provider': broker,\n",
    "                'url': property_url,\n",
    "                'title': title\n",
    "            }\n",
    "            if is_forsale:\n",
    "                properties_list.append(properties)\n",
    "        return properties_list\n",
    "    # except:\n",
    "    #   print (\"Failed to process the page\",url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_sf_area_codes(output_folder):\n",
    "    \"\"\"Scrape from all SF area codes\"\"\"\n",
    "    zipcodes = [94102,\n",
    "             94104,\n",
    "             94103,\n",
    "             94105,\n",
    "             94108,\n",
    "             94107,\n",
    "             94110,\n",
    "             94109,\n",
    "             94112,\n",
    "             94111,\n",
    "             94115,\n",
    "             94114,\n",
    "             94117,\n",
    "             94116,\n",
    "             94118,\n",
    "             94121,\n",
    "             94123,\n",
    "             94122,\n",
    "             94124,\n",
    "             94127,\n",
    "             94126,\n",
    "             94129,\n",
    "             94131,\n",
    "             94133,\n",
    "             94132,\n",
    "             94134,\n",
    "             94139,\n",
    "             94143,\n",
    "             94146,\n",
    "             94151,\n",
    "             94159,\n",
    "             94158,\n",
    "             94188,\n",
    "             94177,\n",
    "             ]\n",
    "    sort = 'newest'\n",
    "    for zipcode in zipcodes:\n",
    "        print (\"Fetching data for %s\" % (zipcode))\n",
    "        scraped_data = parse(str(zipcode), sort)\n",
    "        print (\"Writing data to output file\")\n",
    "        with open(f\"{output_folder}/properties-{zipcode}.csv\", 'wb')as csvfile:\n",
    "            fieldnames = ['title', 'address', 'city', 'state', 'postal_code', 'price', 'facts and features',\n",
    "                          'real estate provider', 'url']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for row in scraped_data:\n",
    "                writer.writerow(row)\n",
    "def run(output_folder: str):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    scrape_all_sf_area_codes(output_folder=output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 94102\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94104\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94103\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94105\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94108\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94107\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94110\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94109\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94112\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94111\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94115\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94114\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94117\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94116\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94118\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94121\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94123\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94122\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94124\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94127\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94126\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94129\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94131\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94133\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94132\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94134\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94139\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94143\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94146\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94151\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94159\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94158\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94188\n",
      "200\n",
      "Writing data to output file\n",
      "Fetching data for 94177\n",
      "200\n",
      "Writing data to output file\n"
     ]
    }
   ],
   "source": [
    "run(output_folder='./data/sf/mar9_2018/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
